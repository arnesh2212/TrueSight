{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-24 23:30:58.778620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-24 23:30:58.793632: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-24 23:30:58.798229: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-24 23:30:58.810080: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-24 23:30:59.648195: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from functools import partial\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "\n",
    "def is_subword(text, tokenized, tokenizer, index):\n",
    "    word = tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"][index])\n",
    "    start_ind, end_ind = tokenized[\"offset_mapping\"][index]\n",
    "    word_ref = text[start_ind:end_ind]\n",
    "    is_subword = len(word) != len(word_ref)\n",
    "    return is_subword\n",
    "\n",
    "\n",
    "def tokenize(example, labels2int, tokenizer, iob=True, ignore_subwords=True):\n",
    "\n",
    "    text, labels = example[\"source_text\"], example[\"privacy_mask\"]\n",
    "\n",
    "    i = 0\n",
    "    token_labels = []\n",
    "\n",
    "    tokenized = tokenizer(text, return_offsets_mapping=True, return_special_tokens_mask=True)\n",
    "    start_token_to_label = {\n",
    "        tokenized.char_to_token(label[\"start\"]): (label[\"start\"], label[\"end\"], label[\"label\"]) for label in labels\n",
    "    }\n",
    "    while i < len(tokenized[\"input_ids\"]):\n",
    "        if tokenized[\"special_tokens_mask\"][i] == 1:\n",
    "            token_labels.append(-100)\n",
    "            i += 1\n",
    "        elif i not in start_token_to_label:\n",
    "            if ignore_subwords and is_subword(text, tokenized, tokenizer, i):\n",
    "                token_labels.append(-100)\n",
    "            else:\n",
    "                token_labels.append(labels2int[\"O\"])\n",
    "            i += 1\n",
    "        else:\n",
    "            start, end, label = start_token_to_label[i]\n",
    "            start_token = tokenized.char_to_token(start)\n",
    "            assert start_token == i\n",
    "            j = start_token\n",
    "            while j < (len(tokenized[\"input_ids\"]) - 1) and tokenized.token_to_chars(j).start < end:\n",
    "                if j == start_token:\n",
    "                    if iob:\n",
    "                        token_labels.append(labels2int[\"B-\" + label])\n",
    "                    else:\n",
    "                        token_labels.append(labels2int[label])\n",
    "                elif ignore_subwords and is_subword(text, tokenized, tokenizer, j):\n",
    "                    token_labels.append(-100)\n",
    "                else:\n",
    "                    if iob:\n",
    "                        token_labels.append(labels2int[\"I-\" + label])\n",
    "                    else:\n",
    "                        token_labels.append(labels2int[label])\n",
    "\n",
    "                j += 1\n",
    "            i = j\n",
    "    tokenized[\"labels\"] = token_labels\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred, label_list, seqeval_metric):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval_metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    results_flat = {f\"{k}_f1\": v[\"f1\"] for k, v in results.items() if isinstance(v, dict)}\n",
    "    results_flat.update(\n",
    "        {\n",
    "            \"precision\": results[\"overall_precision\"],\n",
    "            \"recall\": results[\"overall_recall\"],\n",
    "            \"f1\": results[\"overall_f1\"],\n",
    "            \"accuracy\": results[\"overall_accuracy\"],\n",
    "        }\n",
    "    )\n",
    "    return results_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id =  {\n",
    "    \"0\": \"O\",\n",
    "    \"1\": \"B-CITY\",\n",
    "    \"2\": \"I-CITY\",\n",
    "    \"3\": \"B-FIRSTNAME\",\n",
    "    \"4\": \"I-FIRSTNAME\",\n",
    "    \"5\": \"B-USERNAME\",\n",
    "    \"6\": \"I-USERNAME\",\n",
    "    \"7\": \"B-JOBTYPE\",\n",
    "    \"8\": \"B-PREFIX\",\n",
    "    \"9\": \"I-PREFIX\",\n",
    "    \"10\": \"B-LASTNAME\",\n",
    "    \"11\": \"B-EMAIL\",\n",
    "    \"12\": \"I-EMAIL\",\n",
    "    \"13\": \"B-NEARBYGPSCOORDINATE\",\n",
    "    \"14\": \"I-NEARBYGPSCOORDINATE\",\n",
    "    \"15\": \"B-ACCOUNTNUMBER\",\n",
    "    \"16\": \"I-ACCOUNTNUMBER\",\n",
    "    \"17\": \"B-ACCOUNTNAME\",\n",
    "    \"18\": \"I-ACCOUNTNAME\",\n",
    "    \"19\": \"B-MIDDLENAME\",\n",
    "    \"20\": \"I-MIDDLENAME\",\n",
    "    \"21\": \"B-COUNTY\",\n",
    "    \"22\": \"I-COUNTY\",\n",
    "    \"23\": \"B-AGE\",\n",
    "    \"24\": \"B-CREDITCARDCVV\",\n",
    "    \"25\": \"B-DOB\",\n",
    "    \"26\": \"I-DOB\",\n",
    "    \"27\": \"B-MASKEDNUMBER\",\n",
    "    \"28\": \"I-MASKEDNUMBER\",\n",
    "    \"29\": \"B-PASSWORD\",\n",
    "    \"30\": \"I-PASSWORD\",\n",
    "    \"31\": \"B-SEX\",\n",
    "    \"32\": \"B-STATE\",\n",
    "    \"33\": \"B-COMPANYNAME\",\n",
    "    \"34\": \"I-COMPANYNAME\",\n",
    "    \"35\": \"B-PHONEIMEI\",\n",
    "    \"36\": \"I-PHONEIMEI\",\n",
    "    \"37\": \"B-STREET\",\n",
    "    \"38\": \"I-STREET\",\n",
    "    \"39\": \"B-SSN\",\n",
    "    \"40\": \"I-SSN\",\n",
    "    \"41\": \"B-IPV4\",\n",
    "    \"42\": \"I-IPV4\",\n",
    "    \"43\": \"B-USERAGENT\",\n",
    "    \"44\": \"I-USERAGENT\",\n",
    "    \"45\": \"B-MAC\",\n",
    "    \"46\": \"I-MAC\",\n",
    "    \"47\": \"B-PIN\",\n",
    "    \"48\": \"I-PIN\",\n",
    "    \"49\": \"B-IP\",\n",
    "    \"50\": \"I-IP\",\n",
    "    \"51\": \"B-URL\",\n",
    "    \"52\": \"I-URL\",\n",
    "    \"53\": \"B-CURRENCYSYMBOL\",\n",
    "    \"54\": \"B-DATE\",\n",
    "    \"55\": \"I-DATE\",\n",
    "    \"56\": \"B-TIME\",\n",
    "    \"57\": \"I-TIME\",\n",
    "    \"58\": \"B-VEHICLEVRM\",\n",
    "    \"59\": \"I-VEHICLEVRM\",\n",
    "    \"60\": \"I-AMOUNT\",\n",
    "    \"61\": \"B-ETHEREUMADDRESS\",\n",
    "    \"62\": \"I-ETHEREUMADDRESS\",\n",
    "    \"63\": \"B-BITCOINADDRESS\",\n",
    "    \"64\": \"I-BITCOINADDRESS\",\n",
    "    \"65\": \"B-LITECOINADDRESS\",\n",
    "    \"66\": \"I-LITECOINADDRESS\",\n",
    "    \"67\": \"I-JOBTYPE\",\n",
    "    \"68\": \"B-CREDITCARDNUMBER\",\n",
    "    \"69\": \"I-CREDITCARDNUMBER\",\n",
    "    \"70\": \"B-IPV6\",\n",
    "    \"71\": \"I-IPV6\",\n",
    "    \"72\": \"I-LASTNAME\",\n",
    "    \"73\": \"B-PHONENUMBER\",\n",
    "    \"74\": \"I-PHONENUMBER\",\n",
    "    \"75\": \"B-CREDITCARDISSUER\",\n",
    "    \"76\": \"I-CREDITCARDISSUER\",\n",
    "    \"77\": \"B-SECONDARYADDRESS\",\n",
    "    \"78\": \"I-SECONDARYADDRESS\",\n",
    "    \"79\": \"B-ZIPCODE\",\n",
    "    \"80\": \"I-ZIPCODE\",\n",
    "    \"81\": \"B-VEHICLEVIN\",\n",
    "    \"82\": \"I-VEHICLEVIN\",\n",
    "    \"83\": \"I-AGE\",\n",
    "    \"84\": \"B-GENDER\",\n",
    "    \"85\": \"I-GENDER\",\n",
    "    \"86\": \"B-ORDINALDIRECTION\",\n",
    "    \"87\": \"B-JOBAREA\",\n",
    "    \"88\": \"B-HEIGHT\",\n",
    "    \"89\": \"I-HEIGHT\",\n",
    "    \"90\": \"B-JOBTITLE\",\n",
    "    \"91\": \"I-JOBTITLE\",\n",
    "    \"92\": \"B-BUILDINGNUMBER\",\n",
    "    \"93\": \"I-BUILDINGNUMBER\",\n",
    "    \"94\": \"B-AMOUNT\",\n",
    "    \"95\": \"I-STATE\",\n",
    "    \"96\": \"I-CURRENCYSYMBOL\",\n",
    "    \"97\": \"B-IBAN\",\n",
    "    \"98\": \"I-IBAN\",\n",
    "    \"99\": \"B-BIC\",\n",
    "    \"100\": \"I-BIC\",\n",
    "    \"101\": \"B-EYECOLOR\",\n",
    "    \"102\": \"B-CURRENCYNAME\",\n",
    "    \"103\": \"I-CURRENCYNAME\",\n",
    "    \"104\": \"B-CURRENCY\",\n",
    "    \"105\": \"I-CURRENCY\",\n",
    "    \"106\": \"B-CURRENCYCODE\",\n",
    "    \"107\": \"I-CURRENCYCODE\",\n",
    "    \"108\": \"I-JOBAREA\",\n",
    "    \"109\": \"I-EYECOLOR\",\n",
    "    \"110\": \"I-CREDITCARDCVV\",\n",
    "    \"111\" : \"I-ORDINALDIRECTION\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(label2id.values())\n",
    "label2id = {k: v for v, k in enumerate(labels)}\n",
    "#Invert\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnesh/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/arnesh/.local/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:551: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pretrained_name = \"microsoft/deberta-v3-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(pretrained_name, num_labels=len(labels), id2label=id2label)\n",
    "\n",
    "ds = load_dataset(\"ai4privacy/pii-masking-200k\")\n",
    "# ds = ds.filter(lambda x: x[\"language\"] == \"English\", num_proc=4)\n",
    "ds = ds.map(\n",
    "    partial(tokenize, labels2int=label2id, tokenizer=tokenizer, iob=True, ignore_subwords=True),\n",
    "    batched=False,\n",
    "    remove_columns=[\n",
    "        \"source_text\",\n",
    "        \"target_text\",\n",
    "        \"privacy_mask\",\n",
    "        \"span_labels\",\n",
    "        \"mbert_text_tokens\",\n",
    "        \"mbert_bio_labels\",\n",
    "        \"id\",\n",
    "        \"language\",\n",
    "        \"set\",\n",
    "    ],\n",
    "    num_proc=8,\n",
    ").remove_columns([\"offset_mapping\"])\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"output_DeBERTa_v3_small\",\n",
    "    max_steps=40000,\n",
    "    eval_steps=5000,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    overwrite_output_dir=True,\n",
    "    warmup_ratio=0.2,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    save_steps=5000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=3000,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    torch_compile=False,\n",
    "\n",
    ")\n",
    "test_size = 0.1\n",
    "ds[\"train\"], ds[\"test\"] = ds[\"train\"].train_test_split(test_size=test_size, seed=42)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_arguments,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset= ds[\"test\"],\n",
    "    data_collator=DataCollatorForTokenClassification(tokenizer),\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=partial(compute_metrics, label_list=labels, seqeval_metric=evaluate.load(\"seqeval\")),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer.py:2236\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2233\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2236\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/accelerate/data_loader.py:550\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/trainer_utils.py:814\u001b[0m, in \u001b[0;36mRemoveColumnsCollator.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[\u001b[38;5;28mdict\u001b[39m]):\n\u001b[1;32m    813\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_columns(feature) \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/data/data_collator.py:271\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 271\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    280\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/data/data_collator.py:66\u001b[0m, in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     padded \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m warning_state\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:3481\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[39;00m\n\u001b[1;32m   3478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[1;32m   3479\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3480\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3481\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[43mencoded_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3482\u001b[0m     )\n\u001b[1;32m   3484\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m   3486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'eval_loss': 0.06687254458665848, 'eval_BOD_f1': 0.9671848013816926, 'eval_BUILDING_f1': 0.9815005138746146, 'eval_CARDISSUER_f1': 0.0, 'eval_CITY_f1': 0.9705593719332678, 'eval_COUNTRY_f1': 0.9685138539042821, 'eval_DATE_f1': 0.9226327944572749, 'eval_DRIVERLICENSE_f1': 0.9569736021617129, 'eval_EMAIL_f1': 0.9851541682527598, 'eval_GEOCOORD_f1': 0.9677419354838711, 'eval_GIVENNAME1_f1': 0.8613455510007235, 'eval_GIVENNAME2_f1': 0.7895716945996275, 'eval_IDCARD_f1': 0.939365496527126, 'eval_IP_f1': 0.9852330410706046, 'eval_LASTNAME1_f1': 0.8338430173292558, 'eval_LASTNAME2_f1': 0.7272727272727272, 'eval_LASTNAME3_f1': 0.6918918918918918, 'eval_PASS_f1': 0.933046683046683, 'eval_PASSPORT_f1': 0.9550030819806863, 'eval_POSTCODE_f1': 0.9765013054830287, 'eval_SECADDRESS_f1': 0.9680789320951828, 'eval_SEX_f1': 0.9722222222222222, 'eval_SOCIALNUMBER_f1': 0.9524744697564809, 'eval_STATE_f1': 0.9787023278850916, 'eval_STREET_f1': 0.9688796680497925, 'eval_TEL_f1': 0.970946113732307, 'eval_TIME_f1': 0.9695451549110086, 'eval_TITLE_f1': 0.9568607068607069, 'eval_USERNAME_f1': 0.9333333333333333, 'eval_precision': 0.9410922874603543, 'eval_recall': 0.952028798372266, 'eval_f1': 0.9465289529478127, 'eval_accuracy': 0.992088277633207, 'eval_runtime': 28.7216, 'eval_samples_per_second': 276.656, 'eval_steps_per_second': 8.669, 'epoch': 42.78}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
